# ML Avito

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Machine Learning](https://img.shields.io/badge/ML-Ranking-green)
![Status](https://img.shields.io/badge/Status-Completed-success)

## Структура кода и пояснения к нему

### БЛОК 1: Подготовка и генерация фичей для train (Без загрузки всего датасета в RAM)

Этот блок выполняет предварительную подготовку данных и создает векторизацию текстовых фичей с использованием HashingVectorizer + TF-IDF + SVD. Он работает в 4 этапа:

- Читает размеры train/test (только `query_id`), чтобы не перегружать память.
- Расчитывает глобальный клиппинг цены.
- Создает 5 фолдов по query_id.
- Считает document frequency для двух текстовых комбинаций (`query_text` + `item_title`, `query_text` + `item_description`) через streaming PyArrow, сохраняет HashingVectorizer и IDF-векторы.
- Обучает TruncatedSVD (128 компонент) на сэмпле 300k строк с TF-IDF преобразованием.
- Применяет всего пайплайна к полному train в батчах (30k строк), добавляет engineered фичей (`price_log`, `is_loc_match`, `conv_missing`), SVD-компоненты, сохряняет в частичные parquet.

**Результат**: `train_featurized_parts/*.parquet` (без raw текста, с 256 SVD-фичами).

### БЛОК 2: Подготовка и генерация фичей для test

Идентичный пайплайн для test данных, используя модели/IDF из train. Загружает предобученные трансформеры и price_clip параметры.

- Обрабатывает test в батчах (30k строк), применяет те же фичи + TF-IDF + SVD.
- Сохраняет в `test_featurized_parts/*.parquet` с теми же колонками, что и train.

**Результат**: `test_featurized_parts/*.parquet` (без raw текста, с 256 SVD-фичами).

### БЛОК 3: Обучение CatBoost Ranker

Собирает train/validation из фолдов (val=fold_0, train=folds_1+2 = 40% данных), обучает ranking-модель.

- Загружает частичные parquet, фильтрует по query_id фолдам
- Создает CatBoost Pool с `group_id`=`query_id`, `target`=`item_contact`  
- Обучает CatBoostRanker (YetiRank loss, NDCG@10 метрика, GPU, 3000 итераций)
- Cохраняет модель `catboost_ranker_40pct.cbm`

**Результат**: Обученная модель CatBoost Ranker, готовая для получения предсказаний.

### БЛОК 4: Предсказание и submission

Загружает обученную модель, применяет к test частям, генерирует `solution.csv`.

- Для каждой test части: predict → добавляет score.
- Конкатенирует, сортирует по `query_id` + `score`.
- Сохраняет Сохраняется итоговый файл `solution.csv`.

**Результат**: Готовый submission для ranking-задачи.

## Логика выбора методов

### Выбор модели:  
- **CatBoostRanker** выбран как state‑of‑the‑art градиентный бустинг для задач ранжирования.  
- Преимущества:  
  - Поддержка pairwise loss (`YetiRank`), что напрямую оптимизирует порядок объектов. 
  - Эффективная работа с GPU (ускорение обучения).  
  - Устойчивость к переобучению благодаря регуляризации.

### Признаки (Feature Engineering):
- **Числовые:** цена (`log_price`), конверсия кликов (`item_query_click_conv`).  
- **Категориальные:** совпадение категорий и локаций (`cat_match`, `loc_match`, `mcat_match`).  
- **Текстовые:**  
  - **TF‑IDF + косинусная схожесть** между запросом и заголовком объявления, а также между запросом и описанием объявления.
  - Выбор TF‑IDF обоснован способностью учитывать важность слов в корпусе, что улучшает оценку релевантности.
- **Пропуски в данных** заполнялись в зависимости от смысла переменной.

### Стратегия работы с большими данными:  
- **Батчирование** при вычислении TF‑IDF схожести предотвратило переполнение оперативной памяти.  
- **Использование GPU** (CatBoost с `task_type='GPU'`) ускорило обучение в 3–5 раз.

### Валидация:
- Разбиение по `query_id` (40/20). Были выбраны предельные значения для корректной работы Kaggle-Notebook. 
- Метрика NDCG@10 вычислена с дисконтом `0.97^position`, что соответствует формуле оценивания на платформе.

## Результаты
Удалось достичь точности 0,81 на валидационной выборке и 0,52 на тестовой (в тестовой все объекты новые, чем обусловлена итоговая метрика модели).
